import asyncio
import logging
import random
import pandas as pd
import pandas_ta as ta
from collections import deque
from ak_utils import (
    get_all_etf_spot_realtime, get_etf_daily_history, CORE_ETF_POOL,
    get_all_stock_spot_realtime, get_stock_daily_history, CORE_STOCK_POOL
)
from llm_analyzer import get_llm_score_and_analysis


logger = logging.getLogger(__name__)

async def generate_ai_driven_report(get_realtime_data_func, get_daily_history_func, core_pool):
    """
    èåˆé‡åŒ–åˆ†æä¸LLMåˆ†æï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šçš„ç»Ÿä¸€å‡½æ•°ã€‚
    å‚æ•°:
        get_realtime_data_func: è·å–å®æ—¶æ•°æ®çš„å‡½æ•° (ä¾‹å¦‚ get_all_etf_spot_realtime æˆ– get_all_stock_spot_realtime)
        get_daily_history_func: è·å–å†å²æ—¥çº¿æ•°æ®çš„å‡½æ•° (ä¾‹å¦‚ get_etf_daily_history æˆ– get_stock_daily_history)
        core_pool: æ ¸å¿ƒè§‚å¯Ÿæ±  (ä¾‹å¦‚ CORE_ETF_POOL æˆ– CORE_STOCK_POOL)
    """
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„ç»Ÿä¸€å…¨é¢åˆ†æå¼•æ“...")
    
    # å¹¶è¡Œè·å–å®æ—¶æ•°æ®å’Œæ—¥çº¿è¶‹åŠ¿
    realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
    daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)
    
    realtime_data_df, daily_trends_list = await asyncio.gather(realtime_data_df_task, daily_trends_task)
    
    if realtime_data_df is None:
        return [{"name": "é”™è¯¯", "code": "", "ai_score": 0, "ai_comment": "è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œæ— æ³•åˆ†æã€‚"}]
    
    daily_trends_map = {item['code']: item for item in daily_trends_list}
    
    # å¤ç”¨ç›˜ä¸­ä¿¡å·ç”Ÿæˆå™¨ï¼Œä¼ å…¥å½“å‰ä½¿ç”¨çš„è§‚å¯Ÿæ± 
    intraday_analyzer = _IntradaySignalGenerator(core_pool)
    intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
    
    final_report = []
    for i, signal in enumerate(intraday_signals):
        code = signal['code']
        name = signal['name']
        logger.info(f"æ­£åœ¨è°ƒç”¨LLMåˆ†æ: {name} ({i+1}/{len(intraday_signals)})")
        try:
            daily_trend = daily_trends_map.get(code, {'status': 'æœªçŸ¥'})
            # å¤ç”¨LLMåˆ†æå™¨
            ai_score, ai_comment = await get_llm_score_and_analysis(signal, daily_trend)
            final_report.append({
                **signal,
                "ai_score": ai_score if ai_score is not None else 0,
                "ai_comment": ai_comment
            })
        except Exception as e:
            logger.error(f"å¤„ç†LLMåˆ†æ {name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            final_report.append({**signal, "ai_score": 0, "ai_comment": "å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚"})
        # ä¿æŒç¤¼è²Œçš„è¯·æ±‚é—´éš”
        await asyncio.sleep(random.uniform(1.0, 2.5))
    
    return sorted(final_report, key=lambda x: x.get('ai_score', 0), reverse=True)





async def _get_daily_trends_generic(get_daily_history_func, core_pool):
    """
    è·å–æŒ‡å®šè§‚å¯Ÿæ± ä¸­æ‰€æœ‰é¡¹ç›®çš„æ—¥çº¿è¶‹åŠ¿å’Œè¯¦ç»†æŠ€æœ¯æŒ‡æ ‡ã€‚
    å‚æ•°:
        get_daily_history_func: è·å–å†å²æ—¥çº¿æ•°æ®çš„å‡½æ•°
        core_pool: æ ¸å¿ƒè§‚å¯Ÿæ± 
    """
    analysis_report = []
    for item_info in core_pool:
        try:
            result = await get_daily_history_func(item_info['code'])
            if result is None or result.empty:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸ºç©ºæˆ–æ— æ³•è·å–ã€‚"]})
                continue
            if 'æ”¶ç›˜' not in result.columns and 'close' in result.columns:
                result.rename(columns={'close': 'æ”¶ç›˜'}, inplace=True)
            elif 'æ”¶ç›˜' not in result.columns and 'Close' in result.columns:
                result.rename(columns={'Close': 'æ”¶ç›˜'}, inplace=True)
            
            # æ£€æŸ¥å¹¶ç»Ÿä¸€ 'æˆäº¤é‡' åˆ—å
            if 'æˆäº¤é‡' not in result.columns and 'volume' in result.columns:
                result.rename(columns={'volume': 'æˆäº¤é‡'}, inplace=True)
            elif 'æˆäº¤é‡' not in result.columns and 'Volume' in result.columns:
                result.rename(columns={'Volume': 'æˆäº¤é‡'}, inplace=True)
            
            # ç¡®ä¿ 'æ—¥æœŸ' åˆ—å­˜åœ¨ä¸”æ˜¯æ—¥æœŸç±»å‹ï¼Œå¹¶è®¾ç½®ä¸ºç´¢å¼• (å¦‚æœakshareè¿”å›çš„ä¸æ˜¯)
            if 'æ—¥æœŸ' in result.columns:
                result['æ—¥æœŸ'] = pd.to_datetime(result['æ—¥æœŸ'])
                result.set_index('æ—¥æœŸ', inplace=True)
            elif 'date' in result.columns:
                result['date'] = pd.to_datetime(result['date'])
                result.set_index('date', inplace=True)
            # ç¡®ä¿ç´¢å¼•åç§°ä¸ºNoneï¼Œé¿å…pandas_taé—®é¢˜
            result.index.name = None

            # ç¡®ä¿å…³é”®åˆ—ç°åœ¨å­˜åœ¨
            if 'æ”¶ç›˜' not in result.columns or 'æˆäº¤é‡' not in result.columns:
                 analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®åˆ—ç¼ºå¤±', 'technical_indicators_summary': ["è·å–åˆ°çš„å†å²æ•°æ®ç¼ºå°‘å¿…è¦çš„'æ”¶ç›˜'æˆ–'æˆäº¤é‡'åˆ—ã€‚"]})
                 continue            
            # ç¡®ä¿æ•°æ®è¶³å¤Ÿè®¡ç®—æŒ‡æ ‡ (è‡³å°‘éœ€è¦60æ¡æ‰èƒ½è®¡ç®—60æ—¥å‡çº¿å’Œ60æ—¥æˆäº¤é‡å‡çº¿)
            if len(result) < 60:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³ (å°‘äº60å¤©)', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸è¶³60å¤©ï¼Œéƒ¨åˆ†é•¿æœŸæŒ‡æ ‡æ— æ³•è®¡ç®—ã€‚"]})
                continue

            # è®¡ç®—æ‰€æœ‰éœ€è¦çš„æŒ‡æ ‡
            result.ta.sma(close='æ”¶ç›˜', length=5, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=10, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=20, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=60, append=True)
            
            # è®¡ç®—MACD
            # pandas_ta ç”Ÿæˆçš„MACDåˆ—åé€šå¸¸æ˜¯ MACD_12_26_9, MACDh_12_26_9, MACDs_12_26_9
            result.ta.macd(close='æ”¶ç›˜', append=True) 

            # è®¡ç®—60æ—¥æˆäº¤é‡å‡çº¿
            result.ta.sma(close='æˆäº¤é‡', length=60, append=True, column_name='VOLUME_SMA_60')

            # è·å–æœ€æ–°å’Œå€’æ•°ç¬¬äºŒæ—¥çš„æ•°æ®
            # ç¡®ä¿è¿™äº›è¡Œç´¢å¼•å­˜åœ¨
            if len(result) < 2:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³ (å°‘äº2å¤©)', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸è¶³2å¤©ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚"]})
                continue

            latest = result.iloc[-1]
            prev_latest = result.iloc[-2]

            trend_signals = [] # ç”¨äºå­˜å‚¨æœ¬æ¬¡åˆ†ææå–çš„è¯¦ç»†æŠ€æœ¯ä¿¡å·

            # ----------------------------------------------------
            # å‡çº¿æ•´ä½“æ’åˆ—çŠ¶æ€ (åˆ¤æ–­è¶‹åŠ¿å¼ºåº¦)
            # ----------------------------------------------------
            ma_cols = ['SMA_5', 'SMA_10', 'SMA_20', 'SMA_60']
            if all(col in latest and pd.notna(latest[col]) for col in ma_cols):
                is_bullish_stack = (latest['SMA_5'] > latest['SMA_10'] and
                                    latest['SMA_10'] > latest['SMA_20'] and
                                    latest['SMA_20'] > latest['SMA_60'])
                
                is_bearish_stack = (latest['SMA_5'] < latest['SMA_10'] and
                                    latest['SMA_10'] < latest['SMA_20'] and
                                    latest['SMA_20'] < latest['SMA_60'])

                if is_bullish_stack:
                    trend_signals.append("å‡çº¿å‘ˆå¼ºåŠ¿å¤šå¤´æ’åˆ— (5 > 10 > 20 > 60æ—¥çº¿)ï¼Œè¶‹åŠ¿å¼ºåŠ²ã€‚")
                elif is_bearish_stack:
                    trend_signals.append("å‡çº¿å‘ˆå¼±åŠ¿ç©ºå¤´æ’åˆ— (5 < 10 < 20 < 60æ—¥çº¿)ï¼Œè¶‹åŠ¿ç–²å¼±ã€‚")
                else:
                    trend_signals.append("å‡çº¿æ’åˆ—çº ç¼  (å¤„äºéœ‡è¡æˆ–è¶‹åŠ¿è½¬æ¢æœŸ)ã€‚")
            else:
                trend_signals.append("éƒ¨åˆ†å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­å‡çº¿æ’åˆ—çŠ¶æ€ã€‚") # ç¡®ä¿æœ‰æè¿°

            # ----------------------------------------------------
            # 1. ç§»åŠ¨å¹³å‡çº¿ï¼ˆMAï¼‰å…³ç³»
            # ----------------------------------------------------
            # è‚¡ä»·ä¸å‡çº¿å…³ç³» - ç¡®ä¿é«˜äºå’Œä½äºéƒ½æœ‰ä¿¡å·
            for length in [5, 10, 20, 60]:
                sma_col = f'SMA_{length}'
                if sma_col in latest and pd.notna(latest[sma_col]):
                    if latest['æ”¶ç›˜'] > latest[sma_col]:
                        trend_signals.append(f"è‚¡ä»·é«˜äº{length}æ—¥å‡çº¿ã€‚")
                    else:
                        trend_signals.append(f"è‚¡ä»·ä½äº{length}æ—¥å‡çº¿ã€‚")
                else:
                    trend_signals.append(f"{length}æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­è‚¡ä»·ä¸å‡çº¿å…³ç³»ã€‚") # ç¡®ä¿æœ‰æè¿°

            # å‡çº¿äº¤å‰ï¼ˆé‡‘å‰/æ­»å‰ï¼‰ - ç¡®ä¿é‡‘å‰ã€æ­»å‰å’Œæ’åˆ—éƒ½æœ‰ä¿¡å·
            ma_pairs = [(5, 10), (10, 20), (20, 60)]
            for s_len, l_len in ma_pairs:
                s_col = f'SMA_{s_len}'
                l_col = f'SMA_{l_len}'
                if all(col in latest and col in prev_latest and pd.notna(latest[col]) and pd.notna(prev_latest[col]) for col in [s_col, l_col]):
                    if latest[s_col] > latest[l_col] and prev_latest[s_col] <= prev_latest[l_col]:
                        trend_signals.append(f"{s_len}æ—¥å‡çº¿é‡‘å‰{l_len}æ—¥å‡çº¿ (çœ‹æ¶¨ä¿¡å·)ã€‚")
                    elif latest[s_col] < latest[l_col] and prev_latest[s_col] >= prev_latest[l_col]:
                        trend_signals.append(f"{s_len}æ—¥å‡çº¿æ­»å‰{l_len}æ—¥å‡çº¿ (çœ‹è·Œä¿¡å·)ã€‚")
                    else:
                        if latest[s_col] > latest[l_col]:
                            trend_signals.append(f"{s_len}æ—¥å‡çº¿åœ¨{l_len}æ—¥å‡çº¿ä¸Šæ–¹ï¼Œå¤šå¤´æ’åˆ—å»¶ç»­ã€‚")
                        else:
                            trend_signals.append(f"{s_len}æ—¥å‡çº¿åœ¨{l_len}æ—¥å‡çº¿ä¸‹æ–¹ï¼Œç©ºå¤´æ’åˆ—å»¶ç»­ã€‚")
                else:
                    trend_signals.append(f"{s_len}æ—¥ä¸{l_len}æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­äº¤å‰ä¸æ’åˆ—ã€‚") # ç¡®ä¿æœ‰æè¿°

            # 60æ—¥å‡çº¿è¶‹åŠ¿ - ç¡®ä¿å‘ä¸Šã€å‘ä¸‹å’ŒæŒå¹³éƒ½æœ‰ä¿¡å·
            if 'SMA_60' in latest and 'SMA_60' in prev_latest and pd.notna(latest['SMA_60']) and pd.notna(prev_latest['SMA_60']):
                if latest['SMA_60'] > prev_latest['SMA_60']:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿å‘ä¸Š (ä¸­é•¿æœŸè¶‹åŠ¿ç§¯æ)ã€‚")
                elif latest['SMA_60'] < prev_latest['SMA_60']:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿å‘ä¸‹ (ä¸­é•¿æœŸè¶‹åŠ¿è°¨æ…)ã€‚")
                else:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿æŒå¹³ (ä¸­é•¿æœŸè¶‹åŠ¿ä¸­æ€§)ã€‚")
            else:
                trend_signals.append("60æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­å…¶è¶‹åŠ¿æ–¹å‘ã€‚") # ç¡®ä¿æœ‰æè¿°

            # ----------------------------------------------------
            # 2. MACD æŒ‡æ ‡ - ç¡®ä¿æ‰€æœ‰çŠ¶æ€éƒ½æœ‰æè¿°ï¼ŒåŒ…æ‹¬æ•°æ®ç¼ºå¤±æƒ…å†µ
            # ----------------------------------------------------
            macd_line_col = 'MACD_12_26_9'
            signal_line_col = 'MACDs_12_26_9'
            histogram_col = 'MACDh_12_26_9'

            # æ•´ä½“æ£€æŸ¥MACDç›¸å…³åˆ—æ˜¯å¦å­˜åœ¨ä¸”éç©º
            if all(col in latest and pd.notna(latest[col]) for col in [macd_line_col, signal_line_col, histogram_col]) and \
               all(col in prev_latest and pd.notna(prev_latest[col]) for col in [macd_line_col, signal_line_col, histogram_col]):

                # MACDé‡‘å‰/æ­»å‰ä¿¡å·
                if latest[macd_line_col] > latest[signal_line_col] and prev_latest[macd_line_col] <= prev_latest[signal_line_col]:
                    trend_signals.append("MACDé‡‘å‰ (çœ‹æ¶¨ä¿¡å·)ã€‚")
                elif latest[macd_line_col] < latest[signal_line_col] and prev_latest[macd_line_col] >= prev_latest[signal_line_col]:
                    trend_signals.append("MACDæ­»å‰ (çœ‹è·Œä¿¡å·)ã€‚")
                else:
                    if latest[macd_line_col] > latest[signal_line_col]:
                        trend_signals.append("MACDçº¿åœ¨ä¿¡å·çº¿ä¸Šæ–¹ (å¤šå¤´å»¶ç»­)ã€‚")
                    else:
                        trend_signals.append("MACDçº¿åœ¨ä¿¡å·çº¿ä¸‹æ–¹ (ç©ºå¤´å»¶ç»­)ã€‚")
                
                # MACDçº¿ä¸é›¶è½´å…³ç³» - ç¡®ä¿æ­£è´Ÿéƒ½æœ‰æè¿°
                if latest[macd_line_col] > 0:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´ä¸Šæ–¹ (å¼ºåŠ¿åŒºåŸŸ)ã€‚")
                elif latest[macd_line_col] < 0:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´ä¸‹æ–¹ (å¼±åŠ¿åŒºåŸŸ)ã€‚")
                else:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´é™„è¿‘ (ä¸­æ€§åŒºåŸŸ)ã€‚")
                
                # MACDæŸ±çº¿å˜åŒ– - ç¡®ä¿æ‰€æœ‰å˜åŒ–éƒ½æœ‰æè¿°
                if latest[histogram_col] > 0:
                    if latest[histogram_col] > prev_latest[histogram_col]:
                        trend_signals.append("MACDçº¢æŸ±å¢é•¿ (å¤šå¤´åŠ›é‡å¢å¼º)ã€‚")
                    elif latest[histogram_col] < prev_latest[histogram_col]:
                        trend_signals.append("MACDçº¢æŸ±ç¼©çŸ­ (å¤šå¤´åŠ›é‡å‡å¼±)ã€‚")
                    else:
                        trend_signals.append("MACDçº¢æŸ±æŒå¹³ (å¤šå¤´åŠ›é‡ç»´æŒ)ã€‚")
                elif latest[histogram_col] < 0:
                    if latest[histogram_col] < prev_latest[histogram_col]:
                        trend_signals.append("MACDç»¿æŸ±å¢é•¿ (ç©ºå¤´åŠ›é‡å¢å¼º)ã€‚")
                    elif latest[histogram_col] > prev_latest[histogram_col]:
                        trend_signals.append("MACDç»¿æŸ±ç¼©çŸ­ (ç©ºå¤´åŠ›é‡å‡å¼±)ã€‚")
                    else:
                        trend_signals.append("MACDç»¿æŸ±æŒå¹³ (ç©ºå¤´åŠ›é‡ç»´æŒ)ã€‚")
                else:
                    trend_signals.append("MACDæŸ±çº¿åœ¨é›¶è½´ (å¤šç©ºå¹³è¡¡)ã€‚")
            else:
                trend_signals.append("MACDæŒ‡æ ‡æ•°æ®ç¼ºå¤±æˆ–ä¸å®Œæ•´ï¼Œæ— æ³•åˆ†æã€‚") # ç¡®ä¿æœ‰æè¿°
            
            # ----------------------------------------------------
            # 3. 60æ—¥å†å²æˆäº¤é‡ä¿¡å· - ç¡®ä¿æ­£å¸¸ã€æ”¾å¤§ã€èç¼©éƒ½æœ‰æè¿°
            # ----------------------------------------------------
            volume_col = 'æˆäº¤é‡'
            volume_sma_col = 'VOLUME_SMA_60'

            if volume_col in latest and volume_sma_col in latest and \
               pd.notna(latest[volume_col]) and pd.notna(latest[volume_sma_col]) and latest[volume_sma_col] > 0:
                
                volume_ratio = latest[volume_col] / latest[volume_sma_col]
                if volume_ratio > 2:
                    trend_signals.append("æˆäº¤é‡è¾ƒ60æ—¥å‡é‡æ˜¾è‘—æ”¾å¤§ (é‡èƒ½å¼‚å¸¸æ´»è·ƒ)ã€‚") # æ›´å¼ºçƒˆçš„æè¿°
                elif volume_ratio < 0.5:
                    trend_signals.append("æˆäº¤é‡è¾ƒ60æ—¥å‡é‡æ˜¾è‘—èç¼© (é‡èƒ½æåº¦æ¸…æ·¡)ã€‚") # æ›´å¼ºçƒˆçš„æè¿°
                elif volume_ratio >= 1.5: # è°ƒæ•´é˜ˆå€¼ï¼Œæ›´ç»†è‡´åœ°åˆ†çº§
                    trend_signals.append("æˆäº¤é‡è¾ƒ60æ—¥å‡é‡æ”¾å¤§ (é‡èƒ½æ´»è·ƒ)ã€‚")
                elif volume_ratio <= 0.75: # è°ƒæ•´é˜ˆå€¼
                    trend_signals.append("æˆäº¤é‡è¾ƒ60æ—¥å‡é‡èç¼© (é‡èƒ½æ¸…æ·¡)ã€‚")
                else:
                    trend_signals.append("æˆäº¤é‡æ¥è¿‘60æ—¥å‡é‡ (é‡èƒ½æ­£å¸¸)ã€‚")
            else:
                trend_signals.append("æˆäº¤é‡æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ†æé‡èƒ½æƒ…å†µã€‚") # ç¡®ä¿æœ‰æè¿°

            # ----------------------------------------------------
            # æœ€ç»ˆæŠ¥å‘ŠçŠ¶æ€
            # ----------------------------------------------------
            # è¿™é‡Œå¯ä»¥ä¿æŒåŸºäº20æ—¥å‡çº¿çš„åˆ¤æ–­ï¼Œæˆ–è€…æ›´å¤æ‚ä¸€äº›
            status = 'ğŸŸ¢ ä¸Šå‡è¶‹åŠ¿' if 'SMA_20' in latest and pd.notna(latest['SMA_20']) and latest['æ”¶ç›˜'] > latest['SMA_20'] else 'ğŸ”´ ä¸‹é™è¶‹åŠ¿'
            if status == 'ğŸŸ¢ ä¸Šå‡è¶‹åŠ¿' and 'SMA_20' in latest and 'SMA_60' in latest and pd.notna(latest['SMA_20']) and pd.notna(latest['SMA_60']) and latest['SMA_20'] > latest['SMA_60']:
                 status = 'ğŸŸ¢ å¼ºåŠ¿ä¸Šå‡è¶‹åŠ¿'
            elif status == 'ğŸ”´ ä¸‹é™è¶‹åŠ¿' and 'SMA_20' in latest and 'SMA_60' in latest and pd.notna(latest['SMA_20']) and pd.notna(latest['SMA_60']) and latest['SMA_20'] < latest['SMA_60']:
                 status = 'ğŸ”´ å¼±åŠ¿ä¸‹é™è¶‹åŠ¿'
            else:
                 status = 'ğŸŸ¡ éœ‡è¡è¶‹åŠ¿' # å¢åŠ ä¸€ä¸ªéœ‡è¡æˆ–ç›˜æ•´çš„æè¿°

            analysis_report.append({
                **item_info,
                'status': status, # ä¼ é€’æ›´è¯¦ç»†çš„æ•´ä½“è¶‹åŠ¿æè¿°
                'technical_indicators_summary': trend_signals
            })
        except Exception as e:
            logger.error(f"âŒ åˆ†æ {item_info.get('name', item_info['code'])} æ—¥çº¿æ•°æ®æ—¶å¤±è´¥: {e}", exc_info=True)
            analysis_report.append({**item_info, 'status': 'âŒ åˆ†æå¤±è´¥', 'technical_indicators_summary': [f"æ•°æ®è·å–æˆ–åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}"]}) # ç¡®ä¿é”™è¯¯ä¿¡æ¯ä¹Ÿä¼ é€’ç»™LLM
        await asyncio.sleep(random.uniform(1.0, 2.0)) # ä¿æŒè¯·æ±‚é—´éš”
    return analysis_report

class _IntradaySignalGenerator:
    """å†…éƒ¨è¾…åŠ©ç±»ï¼šç”Ÿæˆç›˜ä¸­é‡åŒ–ä¿¡å· (å¸¦ç›¸å¯¹æˆäº¤é‡)"""
    def __init__(self, item_list): # æ›´æ”¹ etf_list ä¸ºæ›´é€šç”¨çš„ item_list
        self.item_list = item_list
        self.volume_history = {item['code']: deque(maxlen=20) for item in item_list}

    def generate_signals(self, all_item_data_df): # æ›´æ”¹ all_etf_data_df ä¸ºæ›´é€šç”¨çš„ all_item_data_df
        results = []
        for item in self.item_list: 
            item_data_row = all_item_data_df[all_item_data_df['ä»£ç '] == item['code']]
            if not item_data_row.empty:
                current_data = item_data_row.iloc[0]
                self.volume_history[item['code']].append(current_data['æˆäº¤é¢'])
                results.append(self._create_signal_dict(current_data, item))
        return results

    def _create_signal_dict(self, item_series, item_info):
        points = []
        code = item_series.get('ä»£ç ')
        change = item_series.get('æ¶¨è·Œå¹…', 0)
        
        if change > 2.5: points.append("æ—¥å†…å¤§å¹…ä¸Šæ¶¨")
        if change < -2.5: points.append("æ—¥å†…å¤§å¹…ä¸‹è·Œ")
        
        history = list(self.volume_history[code])
        if len(history) > 5:
            current_interval_volume = history[-1] - (history[-2] if len(history) > 1 else 0)
            avg_interval_volume = (history[-1] - history[0]) / (len(history) - 1) if len(history) > 1 else 0
            if avg_interval_volume > 0 and current_interval_volume > avg_interval_volume * 3:
                points.append("æˆäº¤é‡å¼‚å¸¸æ”¾å¤§")

        return {
            'code': code, 
            'name': item_info.get('name'), 
            'price': item_series.get('æœ€æ–°ä»·'), 
            'change': change, 
            'analysis_points': points if points else ["ç›˜ä¸­ä¿¡å·å¹³ç¨³"]
        }
"""
async def get_detailed_analysis_report_for_debug(get_realtime_data_func, get_daily_history_func, core_pool):
   
    "ç”Ÿæˆè¯¦ç»†çš„é‡åŒ–åˆ†ææŠ¥å‘Šï¼Œä¸è°ƒç”¨LLMï¼Œä¸»è¦ç”¨äºè°ƒè¯•ã€‚å‚æ•°åŒ generate_ai_driven_reportã€‚"
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„è°ƒè¯•åˆ†æå¼•æ“ï¼Œä¸è°ƒç”¨LLM...")
    
    # å¹¶è¡Œè·å–å®æ—¶æ•°æ®å’Œæ—¥çº¿è¶‹åŠ¿
    realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
    daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)
    
    realtime_data_df, daily_trends_list = await asyncio.gather(realtime_data_df_task, daily_trends_task)
    
    if realtime_data_df is None:
        return [{"name": "é”™è¯¯", "code": "", "ai_comment": "è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œæ— æ³•åˆ†æã€‚"}]
    
    daily_trends_map = {item['code']: item for item in daily_trends_list}
    
    # å¤ç”¨ç›˜ä¸­ä¿¡å·ç”Ÿæˆå™¨ï¼Œä¼ å…¥å½“å‰ä½¿ç”¨çš„è§‚å¯Ÿæ± 
    intraday_analyzer = _IntradaySignalGenerator(core_pool)
    intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
    
    debug_report = []
    for i, signal in enumerate(intraday_signals):
        code = signal['code']
        name = signal['name']
        logger.info(f"æ­£åœ¨å‡†å¤‡è°ƒè¯•æŠ¥å‘Š: {name} ({i+1}/{len(intraday_signals)})")
        
        daily_trend_info = daily_trends_map.get(code, {'status': 'æœªçŸ¥', 'technical_indicators_summary': []})
        
        debug_report.append({
            'code': code,
            'name': name,
            'price': signal.get('price'),
            'change': signal.get('change'),
            'intraday_signals': signal.get('analysis_points'),
            'daily_trend_status': daily_trend_info.get('status'),
            'technical_indicators_summary': daily_trend_info.get('technical_indicators_summary')
        })
        # ä¿æŒç¤¼è²Œçš„è¯·æ±‚é—´éš”ï¼Œå³ä½¿ä¸è°ƒç”¨LLMä¹Ÿå»ºè®®æœ‰é—´éš”
        await asyncio.sleep(random.uniform(0.5, 1.0)) # å¯ä»¥ç¼©çŸ­å»¶è¿Ÿï¼Œå› ä¸ºä¸è°ƒç”¨LLM

    return debug_report
"""