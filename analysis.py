import asyncio
import logging
import random
import pandas as pd
import pandas_ta as ta
from collections import deque
from ak_utils import (
    get_all_etf_spot_realtime, get_etf_daily_history, CORE_ETF_POOL,
    get_all_stock_spot_realtime, get_stock_daily_history, CORE_STOCK_POOL
)
from llm_analyzer import get_llm_score_and_analysis

logger = logging.getLogger(__name__)

async def generate_ai_driven_report(get_realtime_data_func, get_daily_history_func, core_pool):
    """
    èåˆé‡åŒ–åˆ†æä¸LLMåˆ†æï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šçš„ç»Ÿä¸€å‡½æ•°ã€‚
    å‚æ•°:
        get_realtime_data_func: è·å–å®æ—¶æ•°æ®çš„å‡½æ•° (ä¾‹å¦‚ get_all_etf_spot_realtime æˆ– get_all_stock_spot_realtime)
        get_daily_history_func: è·å–å†å²æ—¥çº¿æ•°æ®çš„å‡½æ•° (ä¾‹å¦‚ get_etf_daily_history æˆ– get_stock_daily_history)
        core_pool: æ ¸å¿ƒè§‚å¯Ÿæ±  (ä¾‹å¦‚ CORE_ETF_POOL æˆ– CORE_STOCK_POOL)
    """
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„ç»Ÿä¸€å…¨é¢åˆ†æå¼•æ“...")
    
    # å¹¶è¡Œè·å–å®æ—¶æ•°æ®å’Œæ—¥çº¿è¶‹åŠ¿
    realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
    daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)
    realtime_data_df, daily_trends_list = await asyncio.gather(realtime_data_df_task, daily_trends_task)
    if realtime_data_df is None:
        return [{"name": "é”™è¯¯", "code": "", "ai_score": 0, "ai_comment": "è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œæ— æ³•åˆ†æã€‚"}]
    daily_trends_map = {item['code']: item for item in daily_trends_list}
    intraday_analyzer = _IntradaySignalGenerator(core_pool)
    intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
    final_report = []
    for i, signal in enumerate(intraday_signals):
        code = signal['code']
        name = signal['name']
        logger.info(f"æ­£åœ¨è°ƒç”¨LLMåˆ†æ: {name} ({i+1}/{len(intraday_signals)})")
        try:
            daily_trend = daily_trends_map.get(code, {'status': 'æœªçŸ¥'})
            ai_score, ai_comment = await get_llm_score_and_analysis(signal, daily_trend)
            final_report.append({
                **signal,
                "ai_score": ai_score if ai_score is not None else 0,
                "ai_comment": ai_comment
            })
        except Exception as e:
            logger.error(f"å¤„ç†LLMåˆ†æ {name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            final_report.append({**signal, "ai_score": 0, "ai_comment": "å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚"})
        await asyncio.sleep(random.uniform(1.0, 2.5))
    return sorted(final_report, key=lambda x: x.get('ai_score', 0), reverse=True)

async def _get_daily_trends_generic(get_daily_history_func, core_pool):
    analysis_report = []
    for item_info in core_pool:
        try:
            result = await get_daily_history_func(item_info['code'])
            if result is None or result.empty:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸ºç©ºæˆ–æ— æ³•è·å–ã€‚"], 'raw_debug_data': {}})
                continue
            # å­—æ®µæ ‡å‡†åŒ–
            if 'æ”¶ç›˜' not in result.columns and 'close' in result.columns:
                result.rename(columns={'close': 'æ”¶ç›˜'}, inplace=True)
            elif 'æ”¶ç›˜' not in result.columns and 'Close' in result.columns:
                result.rename(columns={'Close': 'æ”¶ç›˜'}, inplace=True)
            if 'æ—¥æœŸ' in result.columns:
                result['æ—¥æœŸ'] = pd.to_datetime(result['æ—¥æœŸ'])
                result.set_index('æ—¥æœŸ', inplace=True)
            elif 'date' in result.columns:
                result['date'] = pd.to_datetime(result['date'])
                result.set_index('date', inplace=True)
            result.index.name = None
            result['æ”¶ç›˜'] = pd.to_numeric(result['æ”¶ç›˜'], errors='coerce')
            # æ£€æŸ¥å…³é”®åˆ—
            if 'æ”¶ç›˜' not in result.columns:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®åˆ—ç¼ºå¤±', 'technical_indicators_summary': ["è·å–åˆ°çš„å†å²æ•°æ®ç¼ºå°‘å¿…è¦çš„'æ”¶ç›˜'åˆ—ã€‚"]})
                continue
            if len(result) < 60:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³ (å°‘äº60å¤©)', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸è¶³60å¤©ï¼Œéƒ¨åˆ†é•¿æœŸæŒ‡æ ‡æ— æ³•è®¡ç®—ã€‚"], 'raw_debug_data': {}})
                continue
            # ä»·æ ¼å‡çº¿
            result.ta.sma(close='æ”¶ç›˜', length=5, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=10, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=20, append=True)
            result.ta.sma(close='æ”¶ç›˜', length=60, append=True)
            # MACD
            result.ta.macd(close='æ”¶ç›˜', append=True)
            if len(result) < 2:
                analysis_report.append({**item_info, 'status': 'ğŸŸ¡ æ•°æ®ä¸è¶³ (å°‘äº2å¤©)', 'technical_indicators_summary': ["å†å²æ•°æ®ä¸è¶³2å¤©ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚"], 'raw_debug_data': {}})
                continue
            latest = result.iloc[-1]
            prev_latest = result.iloc[-2]
            trend_signals = []
            ma_debug = {}
            for length in [5, 10, 20, 60]:
                col = f'SMA_{length}'
                val = latest.get(col, None)
                ma_debug[col] = val if pd.notna(val) else None
            raw_debug_data = {
                'æ”¶ç›˜': latest.get('æ”¶ç›˜', None),
                **ma_debug
            }
            for length in [5, 10, 20, 60]:
                col = f'SMA_{length}'
                prev_val = prev_latest.get(col, None)
                raw_debug_data[f"{col}_prev"] = prev_val if pd.notna(prev_val) else None
            ma_values = [f"{col}: {val:.3f}" if val is not None else f"{col}: ç¼ºå¤±" for col, val in ma_debug.items()]
            trend_signals.append("ã€å‡çº¿æœ€æ–°æ•°å€¼ã€‘" + " | ".join(ma_values))
            trend_signals.append(f"æ”¶ç›˜ä»·: {raw_debug_data['æ”¶ç›˜']}")
            # å‡çº¿æ’åˆ—
            ma_cols = ['SMA_5', 'SMA_10', 'SMA_20', 'SMA_60']
            if all(col in latest and pd.notna(latest[col]) for col in ma_cols):
                is_bullish_stack = (latest['SMA_5'] > latest['SMA_10'] and
                                    latest['SMA_10'] > latest['SMA_20'] and
                                    latest['SMA_20'] > latest['SMA_60'])
                is_bearish_stack = (latest['SMA_5'] < latest['SMA_10'] and
                                    latest['SMA_10'] < latest['SMA_20'] and
                                    latest['SMA_20'] < latest['SMA_60'])
                if is_bullish_stack:
                    trend_signals.append("å‡çº¿å‘ˆå¼ºåŠ¿å¤šå¤´æ’åˆ— (5 > 10 > 20 > 60æ—¥çº¿)ï¼Œè¶‹åŠ¿å¼ºåŠ²ã€‚")
                elif is_bearish_stack:
                    trend_signals.append("å‡çº¿å‘ˆå¼±åŠ¿ç©ºå¤´æ’åˆ— (5 < 10 < 20 < 60æ—¥çº¿)ï¼Œè¶‹åŠ¿ç–²å¼±ã€‚")
                else:
                    trend_signals.append("å‡çº¿æ’åˆ—çº ç¼  (å¤„äºéœ‡è¡æˆ–è¶‹åŠ¿è½¬æ¢æœŸ)ã€‚")
            else:
                trend_signals.append("éƒ¨åˆ†å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­å‡çº¿æ’åˆ—çŠ¶æ€ã€‚")
            # è‚¡ä»·ä¸å‡çº¿å…³ç³»
            for length in [5, 10, 20, 60]:
                sma_col = f'SMA_{length}'
                if sma_col in latest and pd.notna(latest[sma_col]):
                    if latest['æ”¶ç›˜'] > latest[sma_col]:
                        trend_signals.append(f"è‚¡ä»·é«˜äº{length}æ—¥å‡çº¿ã€‚")
                    else:
                        trend_signals.append(f"è‚¡ä»·ä½äº{length}æ—¥å‡çº¿ã€‚")
                else:
                    trend_signals.append(f"{length}æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­è‚¡ä»·ä¸å‡çº¿å…³ç³»ã€‚")
            # å‡çº¿äº¤å‰ï¼ˆé‡‘å‰/æ­»å‰ï¼‰
            ma_pairs = [(5, 10), (10, 20), (20, 60)]
            for s_len, l_len in ma_pairs:
                s_col = f'SMA_{s_len}'
                l_col = f'SMA_{l_len}'
                if all(col in latest and col in prev_latest and pd.notna(latest[col]) and pd.notna(prev_latest[col]) for col in [s_col, l_col]):
                    if latest[s_col] > latest[l_col] and prev_latest[s_col] <= prev_latest[l_col]:
                        trend_signals.append(f"{s_len}æ—¥å‡çº¿é‡‘å‰{l_len}æ—¥å‡çº¿ (çœ‹æ¶¨ä¿¡å·)ã€‚")
                    elif latest[s_col] < latest[l_col] and prev_latest[s_col] >= prev_latest[l_col]:
                        trend_signals.append(f"{s_len}æ—¥å‡çº¿æ­»å‰{l_len}æ—¥å‡çº¿ (çœ‹è·Œä¿¡å·)ã€‚")
                    else:
                        if latest[s_col] > latest[l_col]:
                            trend_signals.append(f"{s_len}æ—¥å‡çº¿åœ¨{l_len}æ—¥å‡çº¿ä¸Šæ–¹ï¼Œå¤šå¤´æ’åˆ—å»¶ç»­ã€‚")
                        else:
                            trend_signals.append(f"{s_len}æ—¥å‡çº¿åœ¨{l_len}æ—¥å‡çº¿ä¸‹æ–¹ï¼Œç©ºå¤´æ’åˆ—å»¶ç»­ã€‚")
                else:
                    trend_signals.append(f"{s_len}æ—¥ä¸{l_len}æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­äº¤å‰ä¸æ’åˆ—ã€‚")
            # 60æ—¥å‡çº¿è¶‹åŠ¿
            if 'SMA_60' in latest and 'SMA_60' in prev_latest and pd.notna(latest['SMA_60']) and pd.notna(prev_latest['SMA_60']):
                if latest['SMA_60'] > prev_latest['SMA_60']:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿å‘ä¸Š (ä¸­é•¿æœŸè¶‹åŠ¿ç§¯æ)ã€‚")
                elif latest['SMA_60'] < prev_latest['SMA_60']:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿å‘ä¸‹ (ä¸­é•¿æœŸè¶‹åŠ¿è°¨æ…)ã€‚")
                else:
                    trend_signals.append("60æ—¥å‡çº¿è¶‹åŠ¿æŒå¹³ (ä¸­é•¿æœŸè¶‹åŠ¿ä¸­æ€§)ã€‚")
            else:
                trend_signals.append("60æ—¥å‡çº¿æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­å…¶è¶‹åŠ¿æ–¹å‘ã€‚")
            # MACDæŒ‡æ ‡
            macd_line_col = 'MACD_12_26_9'
            signal_line_col = 'MACDs_12_26_9'
            histogram_col = 'MACDh_12_26_9'
            if all(col in latest and pd.notna(latest[col]) for col in [macd_line_col, signal_line_col, histogram_col]) and \
               all(col in prev_latest and pd.notna(prev_latest[col]) for col in [macd_line_col, signal_line_col, histogram_col]):
                if latest[macd_line_col] > latest[signal_line_col] and prev_latest[macd_line_col] <= prev_latest[signal_line_col]:
                    trend_signals.append("MACDé‡‘å‰ (çœ‹æ¶¨ä¿¡å·)ã€‚")
                elif latest[macd_line_col] < latest[signal_line_col] and prev_latest[macd_line_col] >= prev_latest[signal_line_col]:
                    trend_signals.append("MACDæ­»å‰ (çœ‹è·Œä¿¡å·)ã€‚")
                else:
                    if latest[macd_line_col] > latest[signal_line_col]:
                        trend_signals.append("MACDçº¿åœ¨ä¿¡å·çº¿ä¸Šæ–¹ (å¤šå¤´å»¶ç»­)ã€‚")
                    else:
                        trend_signals.append("MACDçº¿åœ¨ä¿¡å·çº¿ä¸‹æ–¹ (ç©ºå¤´å»¶ç»­)ã€‚")
                if latest[macd_line_col] > 0:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´ä¸Šæ–¹ (å¼ºåŠ¿åŒºåŸŸ)ã€‚")
                elif latest[macd_line_col] < 0:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´ä¸‹æ–¹ (å¼±åŠ¿åŒºåŸŸ)ã€‚")
                else:
                    trend_signals.append("MACDçº¿åœ¨é›¶è½´é™„è¿‘ (ä¸­æ€§åŒºåŸŸ)ã€‚")
                if latest[histogram_col] > 0:
                    if latest[histogram_col] > prev_latest[histogram_col]:
                        trend_signals.append("MACDçº¢æŸ±å¢é•¿ (å¤šå¤´åŠ›é‡å¢å¼º)ã€‚")
                    elif latest[histogram_col] < prev_latest[histogram_col]:
                        trend_signals.append("MACDçº¢æŸ±ç¼©çŸ­ (å¤šå¤´åŠ›é‡å‡å¼±)ã€‚")
                    else:
                        trend_signals.append("MACDçº¢æŸ±æŒå¹³ (å¤šå¤´åŠ›é‡ç»´æŒ)ã€‚")
                elif latest[histogram_col] < 0:
                    if latest[histogram_col] < prev_latest[histogram_col]:
                        trend_signals.append("MACDç»¿æŸ±å¢é•¿ (ç©ºå¤´åŠ›é‡å¢å¼º)ã€‚")
                    elif latest[histogram_col] > prev_latest[histogram_col]:
                        trend_signals.append("MACDç»¿æŸ±ç¼©çŸ­ (ç©ºå¤´åŠ›é‡å‡å¼±)ã€‚")
                    else:
                        trend_signals.append("MACDç»¿æŸ±æŒå¹³ (ç©ºå¤´åŠ›é‡ç»´æŒ)ã€‚")
                else:
                    trend_signals.append("MACDæŸ±çº¿åœ¨é›¶è½´ (å¤šç©ºå¹³è¡¡)ã€‚")
            else:
                trend_signals.append("MACDæŒ‡æ ‡æ•°æ®ç¼ºå¤±æˆ–ä¸å®Œæ•´ï¼Œæ— æ³•åˆ†æã€‚")
            # æœ€ç»ˆæŠ¥å‘ŠçŠ¶æ€
            status = 'ğŸŸ¢ ä¸Šå‡è¶‹åŠ¿' if 'SMA_20' in latest and pd.notna(latest['SMA_20']) and latest['æ”¶ç›˜'] > latest['SMA_20'] else 'ğŸ”´ ä¸‹é™è¶‹åŠ¿'
            if status == 'ğŸŸ¢ ä¸Šå‡è¶‹åŠ¿' and 'SMA_20' in latest and 'SMA_60' in latest and pd.notna(latest['SMA_20']) and pd.notna(latest['SMA_60']) and latest['SMA_20'] > latest['SMA_60']:
                status = 'ğŸŸ¢ å¼ºåŠ¿ä¸Šå‡è¶‹åŠ¿'
            elif status == 'ğŸ”´ ä¸‹é™è¶‹åŠ¿' and 'SMA_20' in latest and 'SMA_60' in latest and pd.notna(latest['SMA_20']) and pd.notna(latest['SMA_60']) and latest['SMA_20'] < latest['SMA_60']:
                status = 'ğŸ”´ å¼±åŠ¿ä¸‹é™è¶‹åŠ¿'
            else:
                status = 'ğŸŸ¡ éœ‡è¡è¶‹åŠ¿'
            analysis_report.append({
                **item_info,
                'status': status,
                'technical_indicators_summary': trend_signals,
                'raw_debug_data': raw_debug_data
            })
        except Exception as e:
            logger.error(f"âŒ åˆ†æ {item_info.get('name', item_info['code'])} æ—¥çº¿æ•°æ®æ—¶å¤±è´¥: {e}", exc_info=True)
            analysis_report.append({**item_info, 'status': 'âŒ åˆ†æå¤±è´¥', 'technical_indicators_summary': [f"æ•°æ®è·å–æˆ–åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}"], 'raw_debug_data': {}})
        await asyncio.sleep(random.uniform(1.0, 2.0))
    return analysis_report


class _IntradaySignalGenerator:
    """å†…éƒ¨è¾…åŠ©ç±»ï¼šç”Ÿæˆç›˜ä¸­é‡åŒ–ä¿¡å·ï¼ˆåªçœ‹ä»·æ ¼æ¶¨è·Œå¹…ï¼‰"""
    def __init__(self, item_list):
        self.item_list = item_list

    def generate_signals(self, all_item_data_df):
        results = []
        for item in self.item_list:
            item_data_row = all_item_data_df[all_item_data_df['ä»£ç '] == item['code']]
            if not item_data_row.empty:
                current_data = item_data_row.iloc[0]
                results.append(self._create_signal_dict(current_data, item))
        return results

    def _create_signal_dict(self, item_series, item_info):
        points = []
        code = item_series.get('ä»£ç ')
        change = item_series.get('æ¶¨è·Œå¹…', 0)
        if change > 2.5: points.append("æ—¥å†…å¤§å¹…ä¸Šæ¶¨")
        if change < -2.5: points.append("æ—¥å†…å¤§å¹…ä¸‹è·Œ")
        return {
            'code': code,
            'name': item_info.get('name'),
            'price': item_series.get('æœ€æ–°ä»·'),
            'change': change,
            'analysis_points': points if points else ["ç›˜ä¸­ä¿¡å·å¹³ç¨³"]
        }
'''
async def get_detailed_analysis_report_for_debug(get_realtime_data_func, get_daily_history_func, core_pool):
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„è°ƒè¯•åˆ†æå¼•æ“ï¼Œä¸è°ƒç”¨LLM...")
    realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
    daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)
    realtime_data_df, daily_trends_list = await asyncio.gather(realtime_data_df_task, daily_trends_task)
    if realtime_data_df is None:
        return [{"name": "é”™è¯¯", "code": "", "ai_comment": "è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œæ— æ³•åˆ†æã€‚"}]
    daily_trends_map = {item['code']: item for item in daily_trends_list}
    intraday_analyzer = _IntradaySignalGenerator(core_pool)
    intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
    debug_report = []
    for i, signal in enumerate(intraday_signals):
        code = signal['code']
        name = signal['name']
        logger.info(f"æ­£åœ¨å‡†å¤‡è°ƒè¯•æŠ¥å‘Š: {name} ({i+1}/{len(intraday_signals)})")
        daily_trend_info = daily_trends_map.get(code, {'status': 'æœªçŸ¥', 'technical_indicators_summary': [], 'raw_debug_data': {}})
        raw_debug_data = daily_trend_info.get('raw_debug_data', {})
        if not raw_debug_data:
            raw_debug_data = {}
        debug_report.append({
            'code': code,
            'name': name,
            'price': signal.get('price'),
            'change': signal.get('change'),
            'intraday_signals': signal.get('analysis_points'),
            'daily_trend_status': daily_trend_info.get('status'),
            'technical_indicators_summary': daily_trend_info.get('technical_indicators_summary'),
            'raw_debug_data': raw_debug_data
        })
        await asyncio.sleep(random.uniform(0.5, 1.0))
    return debug_report
    '''